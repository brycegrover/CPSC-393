# -*- coding: utf-8 -*-
"""HW1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fahhaNFEmle6MJAEf8vosZbosJ88vdcd
"""

from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.compose import make_column_transformer
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
import warnings
warnings.filterwarnings('ignore')

# data and plotting
import pandas as pd
import numpy as np
from plotnine import *

# preprocessing
from sklearn.preprocessing import StandardScaler #Z-score variables
from sklearn.model_selection import train_test_split

# metrics
from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, ConfusionMatrixDisplay, roc_auc_score, recall_score, precision_score

# models
from sklearn.svm import SVC

#Logistic Regression
from sklearn.linear_model import LogisticRegression

#KNN
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neighbors import NearestNeighbors

df = pd.read_csv("https://raw.githubusercontent.com/cmparlettpelleriti/CPSC393ParlettPelleriti/main/Data/hw1.csv")
df = df.dropna()
df.head()

# organize and split data

predictors = [c for c in df.columns if c != "Group"]
X = df[predictors]
y = df["Group"]

random_state = 123 #random state for consistency across model executions

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)

# prep the pipeline

z = make_column_transformer((StandardScaler(), predictors),
                            remainder = "passthrough")
svm = SVC(probability = True)

# build pipeline

pipe = Pipeline([("pre", z),
               ("model", svm)])

# pipe.get_params()

# parameters dict
params = {"model__C": [0.001, 0.01, 1, 5, 25, 50],
          "model__gamma": [0.001, 0.01, 0.1, 0.5, 1,2,5],
          "model__kernel": ["linear", "rbf"]
          }

# grid search

svm_grid = GridSearchCV(pipe, params, scoring = "accuracy", cv = 10, refit = True)

# fit training data
svm_grid.fit(X_train, y_train)

best_kernel = svm_grid.best_params_['model__kernel']
best_C = svm_grid.best_params_['model__C']
best_gamma = svm_grid.best_params_['model__gamma']

print(f"Best kernel: {best_kernel}")
print(f"Best C value: {best_C}")
print(f"Best gamma: {best_gamma}")

#Print out the train and test accuracies for the svm model

svm_train_preds = svm_grid.predict(X_train)
svm_test_preds = svm_grid.predict(X_test)

print(accuracy_score(y_train, svm_train_preds))
print(accuracy_score(y_test, svm_test_preds))

#print out the ROC/AUCs for the svm model

# Predict probabilities for the test set
svm_y_probs = svm_grid.predict_proba(X_test)[:, 1] 
# Get probabilities for the positive class 
#(code found from https://stackoverflow.com/questions/73582838/what-is-predict-proba-and-1-after-x-test-in-code


# Calculate the ROC AUC score
svm_roc_auc = roc_auc_score(y_test, svm_y_probs)

print("ROC/AUC Score: ", svm_roc_auc)

#plot the train and test confusion matrices for the svm model

#calculate confusion matrix for train and test
svm_train_cm = confusion_matrix(y_train,
                            svm_grid.predict(X_train))

svm_test_cm = confusion_matrix(y_test,
                           svm_grid.predict(X_test))

#plot confusion matrix for train and test
disp_train = ConfusionMatrixDisplay(svm_train_cm)
disp_train.plot()
disp_test = ConfusionMatrixDisplay(svm_test_cm)
disp_test.plot()

# prep a new pipeline for logistic regression
lr_z = make_column_transformer((StandardScaler(), predictors),
                            remainder = "passthrough")

#model
lr = LogisticRegression()

# build pipeline for logistic regresion
lr_pipe = Pipeline([("pre", lr_z),
               ("model", lr)])


#lr_pipe.get_params()

#ft lr with training data
lr.fit(X_train, y_train)

#Print out the train and test accuracies for the logistic regerssion model

lr_train_preds = lr.predict(X_train)
lr_test_preds = lr.predict(X_test)

print(accuracy_score(y_train, lr_train_preds))
print(accuracy_score(y_test, lr_test_preds))

#print out the ROC/AUCs for the logistic regression model
# Predict probabilities for the test set
lr_y_probs = lr.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class

# Calculate the ROC AUC score
lr_roc_auc = roc_auc_score(y_test, lr_y_probs)

print("ROC/AUC Score: ", lr_roc_auc)

#calculate confusion matrix for train and test
lr_train_cm = confusion_matrix(y_train,
                            lr.predict(X_train))

lr_test_cm = confusion_matrix(y_test,
                           lr.predict(X_test))

#  plot confusion matrix for train and test
disp_train = ConfusionMatrixDisplay(lr_train_cm)
disp_train.plot()
disp_test = ConfusionMatrixDisplay(lr_test_cm)
disp_test.plot()

# prep a new pipeline for KNN
knn_z = make_column_transformer((StandardScaler(), predictors),
                            remainder = "passthrough")

#model
knn = KNeighborsClassifier()

# Build the pipeline for KNN
knn_pipe = Pipeline([("pre", knn_z), ("model", knn)])

# Choose potential values of k for n_neighbors
k_param = {"model__n_neighbors": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18 , 19, 20,
                             21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]}

# Use GridSearchCV to find the best parameters
knn_grid = GridSearchCV(knn_pipe, k_param, scoring="accuracy", cv=10, refit=True)

knn_grid.fit(X_train, y_train)

# Print the best number of neighbors chosen by GridSearch
print("GridSearch chose", knn_grid.best_estimator_.get_params()["model__n_neighbors"], "k's")

#Print out the train and test accuracies for the logistic knn model
knn_train_preds = knn_grid.predict(X_train)
knn_test_preds = knn_grid.predict(X_test)

print(accuracy_score(y_train, knn_train_preds))
print(accuracy_score(y_test, knn_test_preds))

#print out the ROC/AUCs for the knn model
# Predict probabilities for the test set
knn_y_probs = knn_grid.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class

# Calculate the ROC AUC score
knn_roc_auc = roc_auc_score(y_test, knn_y_probs)

print("ROC/AUC Score: ", knn_roc_auc)

#plot the train and test confusion matrices for the knn model

#calculate confusion matrix for train set
knn_train_cm = confusion_matrix(y_train,
                            knn_grid.predict(X_train))

#calculate confusion matrix for test set
knn_test_cm = confusion_matrix(y_test,
                           knn_grid.predict(X_test))

#  plot confusion matrices for train and test
disp_train = ConfusionMatrixDisplay(knn_train_cm)
disp_train.plot()
disp_test = ConfusionMatrixDisplay(knn_test_cm)
disp_test.plot()

#printing accuracies and ROC/AUCs all in one place

print("SVM Train Acc: ", (accuracy_score(y_train, svm_train_preds) * 100), "% accuracy.")
print("SVM Test Acc: ", (accuracy_score(y_test, svm_test_preds) * 100), "% accuracy.")
print()
print("LR Train Acc: ", (accuracy_score(y_train, lr_train_preds) * 100), "% accuracy.")
print("LR Test Acc: ", (accuracy_score(y_test, lr_test_preds) * 100), "% accuracy.")
print()
print("KNN Train Acc: ", (accuracy_score(y_train, knn_train_preds) * 100), "% accuracy.")
print("KNN Test Acc: ", (accuracy_score(y_test, knn_test_preds) * 100), "% accuracy.")

print()
print()
print()

print("SVM ROC/AUC: ", svm_roc_auc)
print()
print("LR ROC/AUC: ", lr_roc_auc)
print()
print("KNN ROC/AUC: ", knn_roc_auc)